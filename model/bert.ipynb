{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:39.774258Z",
     "start_time": "2024-12-17T21:28:35.191117Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import BertTokenizer, TFBertModel, TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vit\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vit\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:39.977912Z",
     "start_time": "2024-12-17T21:28:39.781263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/weather.csv', sep=';', usecols=[1, 10, 23])\n",
    "df['date_time'] = df.index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['RRR'] = df['RRR'].fillna(0.0)\n",
    "df"
   ],
   "id": "bf9593d832ac4aea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         T                          N  RRR         date_time\n",
       "0     -1.3                      100%.  3.0  16.12.2024 21:00\n",
       "1     -2.0                      100%.  2.0  16.12.2024 18:00\n",
       "2     -1.3                      100%.  0.0  16.12.2024 15:00\n",
       "3     -1.0                      100%.  0.0  16.12.2024 12:00\n",
       "4     -0.9                      100%.  0.4  16.12.2024 09:00\n",
       "...    ...                        ...  ...               ...\n",
       "67385 -6.6                      100%.  0.0  01.02.2005 15:00\n",
       "67386 -7.1  90  или более, но не 100%  0.0  01.02.2005 12:00\n",
       "67387 -8.6                      100%.  3.0  01.02.2005 09:00\n",
       "67388 -8.2                      100%.  2.0  01.02.2005 06:00\n",
       "67389 -8.6                      100%.  0.0  01.02.2005 03:00\n",
       "\n",
       "[67390 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>N</th>\n",
       "      <th>RRR</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.3</td>\n",
       "      <td>100%.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.12.2024 21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>100%.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.12.2024 18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.3</td>\n",
       "      <td>100%.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.12.2024 15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>100%.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.12.2024 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.9</td>\n",
       "      <td>100%.</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.12.2024 09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67385</th>\n",
       "      <td>-6.6</td>\n",
       "      <td>100%.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01.02.2005 15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67386</th>\n",
       "      <td>-7.1</td>\n",
       "      <td>90  или более, но не 100%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01.02.2005 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67387</th>\n",
       "      <td>-8.6</td>\n",
       "      <td>100%.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>01.02.2005 09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67388</th>\n",
       "      <td>-8.2</td>\n",
       "      <td>100%.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>01.02.2005 06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67389</th>\n",
       "      <td>-8.6</td>\n",
       "      <td>100%.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01.02.2005 03:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67390 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.026256Z",
     "start_time": "2024-12-17T21:28:39.995930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def replace_str_with_zero(value):\n",
    "    try:\n",
    "        np.float64(value)\n",
    "        return value\n",
    "    except ValueError:\n",
    "        return np.float64(0)\n",
    "\n",
    "# Применяем функцию ко всем значениям в столбце RRR\n",
    "df['RRR'] = df['RRR'].apply(replace_str_with_zero)\n",
    "df['temperature'] = df['T'].astype(np.float64)\n",
    "df['precipitation'] = df['RRR'].astype(np.float64)\n",
    "\n",
    "del df['T']\n",
    "del df['RRR']\n",
    "df"
   ],
   "id": "5887210ca80ec2e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               N         date_time  temperature  precipitation\n",
       "0                          100%.  16.12.2024 21:00         -1.3            3.0\n",
       "1                          100%.  16.12.2024 18:00         -2.0            2.0\n",
       "2                          100%.  16.12.2024 15:00         -1.3            0.0\n",
       "3                          100%.  16.12.2024 12:00         -1.0            0.0\n",
       "4                          100%.  16.12.2024 09:00         -0.9            0.4\n",
       "...                          ...               ...          ...            ...\n",
       "67385                      100%.  01.02.2005 15:00         -6.6            0.0\n",
       "67386  90  или более, но не 100%  01.02.2005 12:00         -7.1            0.0\n",
       "67387                      100%.  01.02.2005 09:00         -8.6            3.0\n",
       "67388                      100%.  01.02.2005 06:00         -8.2            2.0\n",
       "67389                      100%.  01.02.2005 03:00         -8.6            0.0\n",
       "\n",
       "[67390 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 21:00</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 18:00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 15:00</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 12:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 09:00</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67385</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 15:00</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67386</th>\n",
       "      <td>90  или более, но не 100%</td>\n",
       "      <td>01.02.2005 12:00</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67387</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 09:00</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67388</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 06:00</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67389</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 03:00</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67390 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.042933Z",
     "start_time": "2024-12-17T21:28:40.040578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df['date_time'] = pd.to_datetime(df['date_time'], dayfirst=True)\n",
    "# df['date_time'] = df['date_time'].astype(np.int64)\n",
    "# df['timestamp'] = df['date_time'].apply(lambda x: pd.Timestamp(x))"
   ],
   "id": "9c3ba33214febf06",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.081334Z",
     "start_time": "2024-12-17T21:28:40.078938Z"
    }
   },
   "cell_type": "code",
   "source": "# del df['date_time']",
   "id": "62837b9ff5319282",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.100196Z",
     "start_time": "2024-12-17T21:28:40.094705Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "e432ff0c99973b56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               N         date_time  temperature  precipitation\n",
       "0                          100%.  16.12.2024 21:00         -1.3            3.0\n",
       "1                          100%.  16.12.2024 18:00         -2.0            2.0\n",
       "2                          100%.  16.12.2024 15:00         -1.3            0.0\n",
       "3                          100%.  16.12.2024 12:00         -1.0            0.0\n",
       "4                          100%.  16.12.2024 09:00         -0.9            0.4\n",
       "...                          ...               ...          ...            ...\n",
       "67385                      100%.  01.02.2005 15:00         -6.6            0.0\n",
       "67386  90  или более, но не 100%  01.02.2005 12:00         -7.1            0.0\n",
       "67387                      100%.  01.02.2005 09:00         -8.6            3.0\n",
       "67388                      100%.  01.02.2005 06:00         -8.2            2.0\n",
       "67389                      100%.  01.02.2005 03:00         -8.6            0.0\n",
       "\n",
       "[67390 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 21:00</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 18:00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 15:00</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 12:00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100%.</td>\n",
       "      <td>16.12.2024 09:00</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67385</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 15:00</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67386</th>\n",
       "      <td>90  или более, но не 100%</td>\n",
       "      <td>01.02.2005 12:00</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67387</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 09:00</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67388</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 06:00</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67389</th>\n",
       "      <td>100%.</td>\n",
       "      <td>01.02.2005 03:00</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67390 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.205115Z",
     "start_time": "2024-12-17T21:28:40.135556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prep_n(text):\n",
    "    text = str(text)\n",
    "    f = re.findall(r'\\d+', text)\n",
    "    if len(f):\n",
    "        return np.int32(f[0])\n",
    "    else:\n",
    "        return np.int32(0)\n",
    "df['cloudiness'] = df['N'].apply(lambda x: prep_n(x))"
   ],
   "id": "561cfaea202d85ce",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.229955Z",
     "start_time": "2024-12-17T21:28:40.225265Z"
    }
   },
   "cell_type": "code",
   "source": "df = df[df['temperature'].notna()]",
   "id": "430c5fabf07db264",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.250471Z",
     "start_time": "2024-12-17T21:28:40.247682Z"
    }
   },
   "cell_type": "code",
   "source": "del df['N']",
   "id": "1743fb394671d5bb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:40.275375Z",
     "start_time": "2024-12-17T21:28:40.273054Z"
    }
   },
   "cell_type": "code",
   "source": "df.reset_index(drop=True, inplace=True)",
   "id": "d8f311839a6b6c2f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T21:28:46.020970Z",
     "start_time": "2024-12-17T21:28:40.286298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Токенизация и подготовка данных  \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encodings = tokenizer(df['date_time'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Нормализация целевых значений  \n",
    "scaler = StandardScaler()\n",
    "targets = scaler.fit_transform(df[['temperature', 'precipitation', 'cloudiness']].values)\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки  \n",
    "X_train, X_test, y_train, y_test = train_test_split(encodings['input_ids'], targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем пользовательский датасет  \n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'input_ids': self.inputs[index],\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "    # Создаем датасеты  \n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "# Загружаем модель  \n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "# Переносим модель на GPU  \n",
    "model.to(device)\n",
    "\n",
    "# Определяем оптимизатор  \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Обучение модели  \n",
    "model.train()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "for epoch in range(3):  # Количество эпох  \n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        targets = batch['targets']\n",
    "\n",
    "        outputs = model(input_ids=input_ids, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Сохраняем модель  \n",
    "model.save_pretrained('./weather_model')\n",
    "tokenizer.save_pretrained('./weather_tokenizer')\n",
    "\n",
    "# Функция предсказания  \n",
    "def predict_weather(date):\n",
    "    model.eval()\n",
    "    inputs = tokenizer([date], truncation=True, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits.detach().numpy()\n",
    "    predicted_values = scaler.inverse_transform(predictions)  # Обратная нормализация  \n",
    "    return predicted_values\n",
    "\n",
    "# Пример использования  \n",
    "predicted_values = predict_weather('2024-01-01')\n",
    "print(f'Predicted values for 2024-01-01: Temperature: {predicted_values[0][0]}, '\n",
    "      f'Precipitation: {predicted_values[0][1]}, Cloudiness: {predicted_values[0][2]}')"
   ],
   "id": "ba8841de4fb47563",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 59\u001B[0m\n\u001B[0;32m     56\u001B[0m input_ids \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     57\u001B[0m targets \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtargets\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 59\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[0;32m     61\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1665\u001B[0m, in \u001B[0;36mBertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1657\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1658\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1659\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1660\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1661\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1662\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1663\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1665\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1672\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1673\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1675\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1677\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1679\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pooled_output)\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1078\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1075\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1076\u001B[0m         token_type_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(input_shape, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m-> 1078\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1084\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1086\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1087\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones((batch_size, seq_length \u001B[38;5;241m+\u001B[39m past_key_values_length), device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:211\u001B[0m, in \u001B[0;36mBertEmbeddings.forward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[0;32m    208\u001B[0m         token_type_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(input_shape, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition_ids\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 211\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mword_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m token_type_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken_type_embeddings(token_type_ids)\n\u001B[0;32m    214\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m inputs_embeds \u001B[38;5;241m+\u001B[39m token_type_embeddings\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\hackathon\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2551\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2545\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2546\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2547\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2548\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2549\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2550\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2551\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T22:08:47.545848Z",
     "start_time": "2024-12-17T22:03:11.391759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Разделение данных на тренировочный и тестовый наборы  \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['date_time']], df[['temperature', 'precipitation', 'cloudiness']], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Стандартизация целевых переменных  \n",
    "scaler = StandardScaler()\n",
    "y_train_scaled = scaler.fit_transform(y_train)\n",
    "y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    "# Создание пользовательского датасета  \n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]['date_time']\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "    # Инициализация токенизатора и модели  \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Перенос модели на GPU, если доступен  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Создание DataLoader  \n",
    "train_dataset = WeatherDataset(X_train, y_train_scaled, tokenizer, max_length=10)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Оптимизатор  \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Обучение модели  \n",
    "model.train()\n",
    "for epoch in range(8):  # Установите количество эпох  \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = torch.nn.functional.mse_loss(outputs.logits, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "    if loss.item() < 0.1:\n",
    "        break"
   ],
   "id": "103462f8d0e29286",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.25060153007507324\n",
      "Epoch 2, Loss: 0.6450555324554443\n",
      "Epoch 3, Loss: 0.6049593687057495\n",
      "Epoch 4, Loss: 0.005452822428196669\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T22:26:01.776144Z",
     "start_time": "2024-12-17T22:26:01.424044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Сохраняем модель  \n",
    "model.save_pretrained('./bert_weather_model')\n",
    "tokenizer.save_pretrained('./bert_weather_model')"
   ],
   "id": "ab70e33f25ca5821",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./weather_model\\\\tokenizer_config.json',\n",
       " './weather_model\\\\special_tokens_map.json',\n",
       " './weather_model\\\\vocab.txt',\n",
       " './weather_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:07:56.395865Z",
     "start_time": "2024-12-17T23:07:56.391798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "# Сохранить  \n",
    "joblib.dump(scaler, './bert_weather_model/scaler.pkl')\n",
    "\n",
    "# Затем при необходимости загрузить  \n",
    "scaler = joblib.load('./bert_weather_model/scaler.pkl')"
   ],
   "id": "69252d40627db660",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:07:13.441438Z",
     "start_time": "2024-12-17T23:07:13.178810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Загрузка токенизатора  \n",
    "tokenizer = BertTokenizer.from_pretrained(\"./bert_weather_model\")\n",
    "\n",
    "# Загрузка модели  \n",
    "model = BertForSequenceClassification.from_pretrained(\"./bert_weather_model\")\n",
    "\n",
    "# Переносим модель на устройство (GPU или CPU)  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ],
   "id": "226b8b5a8ebbb6d0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:07:17.419387Z",
     "start_time": "2024-12-17T23:07:17.416293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция для предсказания  \n",
    "def predict(date):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            date,\n",
    "            add_special_tokens=True,\n",
    "            max_length=10,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = scaler.inverse_transform(outputs.logits.cpu().numpy())\n",
    "\n",
    "        return predictions"
   ],
   "id": "1c956d6d5a30df3d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:07:19.796343Z",
     "start_time": "2024-12-17T23:07:19.773867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Пример использования  \n",
    "predicted_values = predict('14.08.2015')\n",
    "print(f'Predicted Temperature: {predicted_values[0][0]}, Precipitation: {predicted_values[0][1]}, Cloudiness: {predicted_values[0][2]}')"
   ],
   "id": "ac1c7e42c59252df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Temperature: 19.090984344482422, Precipitation: 0.6197971701622009, Cloudiness: 50.15557861328125\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f5cdb5173be47418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_weather(date):\n",
    "    model.eval()\n",
    "    inputs = tokenizer([date], truncation=True, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1).numpy()\n",
    "    return predictions\n",
    "\n",
    "# Пример использования  \n",
    "predicted_values = predict_weather('2024-01-01')\n",
    "print(f'Predicted values for 2024-01-01: Temperature: {predicted_values[0][0]}, Precipitation: {predicted_values[0][1]}, Cloudiness: {predicted_values[0][2]}')  "
   ],
   "id": "98f9a24f67b50139"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
