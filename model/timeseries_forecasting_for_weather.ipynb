{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1+rocm6.2\n",
      "GPU доступен: True\n",
      "Название устройства: AMD Radeon RX 7800 XT\n",
      "Using device: cuda\n",
      "Running on AMD GPU with ROCm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(\"GPU доступен:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Название устройства:\", torch.cuda.get_device_name(0))\n",
    "use_gpu = torch.cuda.is_available()\n",
    "is_amd = torch.version.hip is not None\n",
    "device = 'cuda' if use_gpu else 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "if is_amd:\n",
    "    print(\"Running on AMD GPU with ROCm\")\n",
    "elif use_gpu:\n",
    "    print(\"Running on NVIDIA GPU with CUDA\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TensorFlow version: 2.16.1\n",
      "GPU доступны: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Собран с поддержкой ROCm: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f' TensorFlow version: {tf.__version__}')\n",
    "print(\"GPU доступны:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Собран с поддержкой ROCm:\", tf.test.is_built_with_rocm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "Matplotlib version: 3.9.2\n",
      "Pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "import matplotlib\n",
    "print(f'Matplotlib version: {matplotlib.__version__}')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(f'Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efee97fa06e14e5a9ebae78de6e2758f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f434f7b694a1410fb9b9ab2b2239fd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.png:   0%|          | 0.00/6.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c08041f1004080aa4d779da939b474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22088676fe2948e8a72299198c708272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e874440a2b84692b82b8e55a9e9e208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "keras_metadata.pb:   0%|          | 0.00/9.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb72f58a46ec4cd993af85724576cded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "saved_model.pb:   0%|          | 0.00/731k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bc1d5b6c614a3a949d05a08f454a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)tfevents.1655016203.c0811bc66fbd.72.0.v2:   0%|          | 0.00/240k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f52f5bdaaf4132ba37a62a1f4e70bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "variables.data-00000-of-00001:   0%|          | 0.00/66.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fc0bbaa4f74f4789d9d12509105513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)tfevents.1655016252.c0811bc66fbd.72.1.v2:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb386b94cf44f7887b80e6dc9ec1ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "variables.index:   0%|          | 0.00/1.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 05:59:22.163357: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-27 05:59:22.163430: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-27 05:59:22.163451: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-27 05:59:22.163644: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-27 05:59:22.163668: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-27 05:59:22.163692: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:926] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-27 05:59:22.163701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15152 MB memory:  -> device: 0, name: AMD Radeon RX 7800 XT, pci bus id: 0000:03:00.0\n"
     ]
    }
   ],
   "source": [
    "# Note: 'keras<3.x' or 'tf_keras' must be installed (legacy)\n",
    "# See https://github.com/keras-team/tf-keras for more details.\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "\n",
    "model = from_pretrained_keras(\"keras-io/timeseries_forecasting_for_weather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 120, 7)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                5120      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5153 (20.13 KB)\n",
      "Trainable params: 5153 (20.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of synthetic data: (10, 120, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Параметры синтетических данных\n",
    "num_samples = 10  # Количество примеров\n",
    "time_steps = 120  # Длина временного окна\n",
    "num_features = 7  # Количество признаков\n",
    "\n",
    "# Генерация синтетических данных\n",
    "synthetic_data = np.random.random((num_samples, time_steps, num_features))\n",
    "\n",
    "print(\"Shape of synthetic data:\", synthetic_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 06:16:22.033056: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at cudnn_rnn_ops.cc:1779 : INVALID_ARGUMENT: ROCm MIOpen only supports packed input output.\n",
      "2024-12-27 06:16:22.033078: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: ROCm MIOpen only supports packed input output.\n",
      "\t [[{{node CudnnRNNV3}}]]\n",
      "2024-12-27 06:16:22.033091: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: {{function_node __inference_gpu_lstm_with_fallback_7106_specialized_for_model_lstm_PartitionedCall_at___inference_predict_function_7298}} {{function_node __inference_gpu_lstm_with_fallback_7106_specialized_for_model_lstm_PartitionedCall_at___inference_predict_function_7298}} ROCm MIOpen only supports packed input output.\n",
      "\t [[{{node CudnnRNNV3}}]]\n",
      "\t [[model/lstm/PartitionedCall]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node CudnnRNNV3 defined at (most recent call last):\n<stack traces unavailable>\nROCm MIOpen only supports packed input output.\n\t [[{{node CudnnRNNV3}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_predict_function_7298]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Прогнозирование\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msynthetic_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of predictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/rocm/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/rocm/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node CudnnRNNV3 defined at (most recent call last):\n<stack traces unavailable>\nROCm MIOpen only supports packed input output.\n\t [[{{node CudnnRNNV3}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_predict_function_7298]"
     ]
    }
   ],
   "source": [
    "# Прогнозирование\n",
    "predictions = model.predict(synthetic_data)\n",
    "\n",
    "print(\"Shape of predictions:\", predictions.shape)\n",
    "print(\"First prediction:\", predictions[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
